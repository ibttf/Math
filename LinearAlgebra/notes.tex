\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{latexsym,amsfonts,amssymb,amsthm,amsmath}
\usepackage{geometry}
\usepackage{tcolorbox}  % For boxed environments
\usepackage{xcolor}     % For text colors
\usepackage[dvipsnames]{xcolor}
\geometry{margin=1in}

\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

% Custom command for solutions
\newcommand{\solution}{\noindent\textbf{Solution:}\par\nopagebreak}

% Custom boxed environment for definitions
\newtcolorbox{definitionbox}[1][]{
    colback=blue!5!white,
    colframe=blue!75!black,
    fonttitle=\bfseries,
    title=Definition,
    #1
}

% Custom boxed environment for key concepts in solutions
\newtcolorbox{keyconceptbox}[1][]{
    colback=red!5!white,
    colframe=red!75!black,
    fonttitle=\bfseries,
    title=Key Concept,
    #1
}

% Custom boxed environment for a black note
\newtcolorbox{note}[1][]{colback=white, colframe=black, title=Note, fonttitle=\bfseries, #1}




% Custom commands for difficulty levels with practice quetsions
\newcommand{\easy}[1]{\noindent\textcolor{OliveGreen}{\textbf{EASY:}} #1 \par}
\newcommand{\medium}[1]{\noindent\textcolor{orange}{\textbf{MEDIUM:}} #1 \par}
\newcommand{\hard}[1]{\noindent\textcolor{red}{\textbf{HARD:}} #1 \par}
\newcommand{\example}[1]{\noindent\textcolor{black}{\textbf{EXAMPLE:}} #1 \par}

% Custom command for a definition which will be bolded
\newcommand{\definition}[2]{
  \noindent\textbf{#1:} #2
}

\title{Linear Algebra \\ MATH 1201}
\author{Roy Lee}
\date{}  % No date

\begin{document}

\maketitle

\section{Linear Equations in Linear Algebra}

\subsection*{1.1 Systems of Linear Equations}

\definition{Linear equation}{An equation of the form $a_1x_1 + a_2x_2 + \cdots + a_nx_n = b$ where $a_1, a_2, \ldots, a_n, b$ are constants and $x_1, x_2, \ldots, x_n$ are variables.}

\definition{Solution set}{All possible solutions to a system of linear equations.}


If we have a system of linear equations that looks like:
\[
\begin{aligned}
    x_1 & - 2x_2 & + x_3 & = 0 \\
        & \phantom{x_1}x_2 & + 2x_3 & = 3 \\
    3x_1 & + x_2 & + 3x_3 & = 3
\end{aligned}
\]

\definition{Coefficient matrix}{Rewrite system of linear equations as just coefficients}
\[
\begin{bmatrix}
    1 & -2 & 1 \\
    0 & 1 & 2 \\
    3 & 1 & 3
\end{bmatrix}
\]

\definition {Augmented matrix}{Rewrite system as matrix with coefficients and constants}
\[
\begin{bmatrix}
    1 & -2 & 1 & \vert & 0 \\
    0 & 1 & 2 & \vert & 3 \\
    3 & 1 & 3 & \vert & 3
\end{bmatrix}
\]


\definition{Row equivalent}{Two matrices are row equivalent if one can be obtained from the other by a sequence of elementary row operations.}

\definition{Consistent}{A system of linear equations is consistent if it has one or infinitely many solutions.}

\begin{keyconceptbox}
    \textbf{Inconsistent system:}
    A system of linear equations is inconsistent if the RREF of its augmented matrix has a row with $\begin{bmatrix}0 & 0 & 0 & \cdots & 0 & \vert &  b \end{bmatrix}$ where $b \neq 0$.
\end{keyconceptbox}

\subsection*{1.2 Row Reduction and Echelon Forms}

\begin{definitionbox}
    \textbf{Properties of a matrix in echelon form (or reduced echelon form)}
    \begin{itemize}
        \item All nonzero rows are above any rows of all zeros.
        \item The leading entry of each nonzero row occurs to the right of the leading entry of the previous row.
        \item The leading entry in any nonzero row is 1.
        \item All entries in the column below the leading 1 are zeros.
    \end{itemize}
    Example:
    \[
    \begin{bmatrix}
        1 & 2 & 0 & 3 \\
        0 & 1 & 3 & 4 \\
        0 & 0 & 1 & 5
    \end{bmatrix}
    \]
\end{definitionbox}



\begin{definitionbox}
    \textbf{Properties of a matrix in RREF (row-reduced echelon form)}
    \begin{itemize}
        \item Echelon form
        \item The leading entry in each row is a 1.
        \item Each leading 1 is the only nonzero entry in its column.
    \end{itemize}
    Example:
    \[
    \begin{bmatrix}
        1 & 0 & 0 & 2 \\
        0 & 1 & 0 & 3 \\
        0 & 0 & 1 & 4
    \end{bmatrix}
    \]
    \begin{note}
        The RREF of a matrix is unique.
    \end{note}
\end{definitionbox}

\vspace{20px}
\definition{Pivot positions}{The positions of the leading 1s in a matrix in RREF. Obviously, \textbf{pivot columns} and \textbf{pivot rows} are the corresponding rows/columns to pivot positions.}

\definition{Free variables}{Variables that are not pivot variables.}

For example, in this augmented matrix:
\[
    \begin{bmatrix}
    
    1 & 0 & 0 & \vert & 3 \\
    0 & 1 & 2 & \vert & 3 \\

    \end{bmatrix}
\]

$x_1$ and $x_2$ are \textbf{pivot variables}, and $x_3$ is a \textbf{free variable}.


\begin{note}
    If a system of linear equations has \textbf{any} free variables, it has infinitely many solutions.
\end{note}

\definition{Parametric descriptions of solution sets}{
    The standard is to use free variables as our parametric variables. If our RREF form looks like:
    \[
    \begin{bmatrix}
        1 & -3 & -4 & \vert & 0 \\
        0 & 0 & 0 & \vert & 0 \\
        0 & 0 & 0 & \vert & 0
    \end{bmatrix}
    \]
    then $x_2$ and $x_3$ are free variables, which we'll parameterize and write our solution set as:
    \[
    \begin{aligned}
        x_1 & = 3x_2 + 4x_3 \\
        x_2 & = x_2 \\
        x_3 & = x_3
    \end{aligned}
    \]
}

\subsection*{1.3 Vector Equations}
\definition{Column Vector}{A matrix with only one column. These are expressed as 
\[
\textbf{u} = \begin{bmatrix} 3\\-1 \end{bmatrix}
or\ (3, -1)
\]}

The geometric visualization of a vector such as $\begin{bmatrix} 3\\1 \end{bmatrix}$ is a vector in the plane from (0,0) to (3,1).

\begin{note}
    \textbf{Parallelogram Rule for Addition}
    The sum \textbf{u +v} of two column vectors {\bf u} and {\bf v} is the fouth point of the parallelogram with sides given by {\bf(0,0)}, {\bf u}, and {\bf v}.
\end{note}

\begin{keyconceptbox}
    A vector equation
    \[
    x_1a_1 + x_2a_2 + \cdots + x_na_n = b\]
    has the same solution set as the system whose augmented matrix is:
    \[
    \begin{bmatrix}
        a_1 & a_2 & \cdots & a_n & \vert & b
    \end{bmatrix}
    \]
\end{keyconceptbox}

\definition{Span}{The set of all possible linear combinations of a set of vectors. Thus, asking whether a vector \textbf{b} is in the span of a system is the same as asking if the system with b has a solution.}

\subsection*{1.4 The Matrix Equation Ax = b}
This section is very obvious. If there is an \textit{m} x \textit{n} matrix \textit{A} , then we can write Ax=b, which has the same solution set as the the system whose augmented matrix is 
$$
\begin{bmatrix}

    a_{11} & a_{12} & \cdots & a_{1n} & \vert & b_1 \\
    a_{21} & a_{22} & \cdots & a_{2n} & \vert & b_2 \\
    \vdots & \vdots & \ddots & \vdots & \vert & \vdots \\
    a_{m1} & a_{m2} & \cdots & a_{mn} & \vert & b_m
\end{bmatrix}$$

\begin{definitionbox}

    \textbf{The following are logically equivalent}
    \begin{itemize}
        \item For each b in $\mathbb{R}^m$, the equation Ax=b has a solution.
        \item Each b in $\mathbb{R}^m$ is a linear combination of the columns of A.
        \item The columns of A span $\mathbb{R}^m$.
        \item A has a pivot position in every row.
    \end{itemize}
\end{definitionbox}

\subsection* {1.5 Solution Sets of Linear Systems}
\definition{Homogeneous Linear Systems}{A system is homogeneous if it can be written in the form \textit{Ax=0}, where 0 is the zero vector in $\mathbb{R}^m$}.
\begin{note}
    The homogeneous equation \textit{Ax=0} has a \textbf{nontrivial solution} if and only if the equation has \textbf{at least one free variable}
\end{note}

\example{Determine whether the following system is consistent. If so, describe the solution set.}
\[
    \begin{aligned}
        3x_1 & + 5x_2 & -4_3 & = 0 \\
        -3x_1    &  - 2x_2 & +4x_3 & = 0 \\
        6x_1 & + x_2 &  -8x_3 & = 0
    \end{aligned}
\]
Reduce it part way to get to this echelon form:

\[
\begin{bmatrix}
    3 & 5 & -4 & \vert & 0 \\
    0 & 3 & 0 & \vert & 0 \\
    0 & 0 & 0 & \vert & 0
    
\end{bmatrix}\]
Notice $x_3$ is free, so this homogeneous system of equations has a free variable at $x_3$, which means there is a nontrivial solution.
\newline
Reduce it further to get 
\[
\begin{bmatrix}
    1 & 0 & -\frac{4}{3} & \vert& 0\\
    0 & 1 & 0 & \vert&0\\
    0 & 0 & 0 &\vert& 0
\end{bmatrix}
\]
Now, you can rewrite this as the general solution, which is shown below
\begin{keyconceptbox}
    \textbf{General solution to a system of linear equations (example)}
    \[
        \textbf{x} = \begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix} =  \begin{bmatrix}\frac{4}{3}x_3\\0\\x_3\end{bmatrix} = x_3\begin{bmatrix}\frac{4}{3}\\0\\1\end{bmatrix} 
    \]
    We'll factor out the $x_3$ to get the general solution, and this will extend later on to all the other variables, as well as constants, which you'll see later.
\end{keyconceptbox}

\definition{Nonhomogeneous Systems}{These are systems that are not of the form $Ax=0$, but of the form $Ax=b$ where \(b \neq 0\)}
If we had an example of a nonhomogeneous system, the general solution might be writtten in the form:

\[
    \begin{bmatrix}
        x_1\\x_2\\x_3
    \end{bmatrix} =
    \begin{bmatrix}
        -1 + \frac{4}{3}x_3\\2\\x_3
    \end{bmatrix}
     = 
     \begin{bmatrix}
         -1\\2\\0
    \end{bmatrix} + x_3
    \begin{bmatrix}
        \frac{4}{3}\\0\\1
    \end{bmatrix}
\]

\begin{note}
    The solution set of $Ax=b$ is the set of all vectors of the form $w=p+v_h$ where $v_h$ is the solution of the homogeneous equation $Ax=0$.
\end{note}


\subsection*{1.6 Applications of Systems of Linear Equations}
TLDR: we use systems of linear equations for a lot of irl things.

\subsection*{1.7 Linear Independence}

\begin{definitionbox}
    \textbf{Linear Independence}
    \begin{itemize}
        \item  A set of vectors is \textbf{linearly independent} if the only solution to the equation $c_1v_1 + c_2v_2 + \cdots + c_kv_k = 0$ is $c_1=c_2=\cdots=c_k=0$.
        \item The set ${v_1,v_2,\cdot,v_p}$ is said to be \textbf{linearly dependent} if there exists weights $c_1,c_2,\cdots,c_p$ \textbf{not all zero} such that $c_1v_1+c_2v_2+\cdots+c_pv_p=0$.  
    \end{itemize}
   
\end{definitionbox}
\vspace{20px}
\example{Determine whether the following set of vectors is linearly independent}
\[
    v_1 = \begin{bmatrix}
    
        1 \\ 2 \\ 3
    \end{bmatrix}
    v_2 = \begin{bmatrix}
        4\\5\\6
    \end{bmatrix}
    v_3 = \begin{bmatrix}
        2\\1\\0
    \end{bmatrix}
\]
\solution
We must determine if there is a nontrivial solution. Row operations on the associated augmented matrix show that
\[
\begin{bmatrix}
1 & 4 & 2 & \vert & 0\\
2 & 5 & 1 & \vert & 0\\
3 & 6 & 0 & \vert & 0
\end{bmatrix}=
\begin{bmatrix}
1 & 4 & 2 & \vert & 0\\
0 & 1 & 1 & \vert & 0\\
0 & 0 & 0 & \vert & 0
\end{bmatrix}
\]
\begin{keyconceptbox}
    $x_3$ is free, meaning there are infinite solutions and there exists a nontrivial solution.
    \textbf{Thus, the set of vectors is linearly dependent.}

\end{keyconceptbox}

\vspace{20px}

\example{For the above example, find a linear dependence relation among $v_1$, $v_2$, and $v_3$}
\solution
To find a linear dependence relation, completely row reduce and write the new system.

\[
\begin{bmatrix}
    1 & 0 & -2 & \vert & 0\\
    0 & 1 & 1 & \vert & 0\\
    0 & 0 & 0 & \vert & 0
    \end{bmatrix}
 =
\begin{aligned}
    x_1 & \phantom{x_2} & - 2x_3 & = 0 \\
    \phantom{x_1} & x_2 &  + x_3 & = 0\\
    \phantom{x_1} & \phantom{x_2} & 0 & = 0
\end{aligned}
\]
\begin{keyconceptbox}
    \textbf{Linear dependence relation}
    \newline
    \newline
    Thus, $x_1 = 2x_3$ and $x_2 = -x_3$. We can write this as one of infinitely many linear dependence relation:
\[
    10v_1 - 5v_2 + 5v_3 = 0
\]

Note that linear dependence relations are always of the form:
\[
    c_1v_1 + c_2v_2 + \cdot + c_pv_p = 0
\]
\end{keyconceptbox}

\begin{keyconceptbox}
    \definition{Linear independence of matrix columns}{Suppose we begin with a matrix 
    \[A=\begin{bmatrix}
        a_1 & a_2 & \cdots & a_n
    \end{bmatrix}\]}
    The columns of matrix A are \textbf{linearly independent} if and only if the equation $Ax=0$ has \textit{only} the trivial solution.
    \newline
    \newline
    OR
    \newline
    \newline
    Linear independence means there are \textbf{no free variables} in $Ax=0$
\end{keyconceptbox}

\example{Determine if the columns of the matrix $A=\begin{bmatrix}
    0 & 1 & 4 \\
    1 & 2 & -1 \\
    5 & 8 & 0
\end{bmatrix}$ are linearly independent}
\solution
Row reduce it a bit \[
\begin{bmatrix}
    1 & 2 & -1 & 0\\
    0 & 1 & 4 & 0\\
    0 & 0 & 13 & 0
\end{bmatrix}
\]
Observe there are \textbf{no free variables}, so the equation \textbf{$Ax=0$ has only the trivial solution}, and the columns of A are linearly independent.

\definition{Linear independence of a single vector}{
    A set containing only one vector $v$ is linearly independent if and only if $v \neq 0$.
}

\example{
    Determine if the following set of vectors is linearly independent:
    \[
        v_1 = \begin{bmatrix}
            3\\1
        \end{bmatrix}
        v_2 = \begin{bmatrix}
            6\\2
        \end{bmatrix}
    \]
}
\solution
Notice that $v_2$ is a multiple of $v_1$ and thus, the set is linearly dependent.
\newline
\newline
Alternatively, notice that if we wrote this as an augmented matrix of the form $Ax=0$, we'd have $
\begin{bmatrix}
    3 & 1 & \vert & 0\\
    6 & 2 & \vert & 0
\end{bmatrix}$

which would simplify to $\begin{bmatrix}
    1 & \frac{1}{3} & \vert & 0\\
    0 & 0 & \vert & 0
\end{bmatrix}$
giving us the free variable $x_2$, thus linear dependence.

\begin{note}
    If a set $S={v_1,v_2, ... ,v_p}$ in $\mathbb{R}^m$ contains the zero vector, then the set is linearly dependent.
    \newline
    \newline
    If a set contains more vectors than there are entires in each vector, then the set is linearly independent.
\end{note}

\end{document}
